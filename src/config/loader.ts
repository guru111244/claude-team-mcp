/**
 * é…ç½®åŠ è½½å™¨æ¨¡å—
 * æ”¯æŒ YAML æ–‡ä»¶é…ç½®å’Œç¯å¢ƒå˜é‡è¦†ç›–
 * 
 * å¿«é€Ÿå¯åŠ¨ï¼šåªéœ€è®¾ç½®ä¸€ä¸ª API Key å³å¯è¿è¡Œï¼
 * - GEMINI_API_KEY / ANTHROPIC_API_KEY / OPENAI_API_KEY
 * - æˆ– CLAUDE_TEAM_API_KEY (å•ä¸€ Key æ¨¡å¼)
 */

import { readFileSync, existsSync } from 'node:fs';
import { join } from 'node:path';
import { parse } from 'yaml';
import { ConfigSchema, type Config } from './schema.js';

/** æ¨¡å‹æä¾›å•†ç±»å‹ */
type Provider = 'gemini' | 'anthropic' | 'openai' | 'ollama';

/**
 * ç¯å¢ƒå˜é‡æ¨¡å‹é…ç½®
 */
interface EnvModelConfig {
  provider: Provider;
  model: string;
  baseUrl?: string;
  apiKey?: string;
  temperature?: number;
  maxTokens?: number;
}

/** æ¨¡å‹ç¯å¢ƒå˜é‡åŒ¹é…æ¨¡å¼ */
const MODEL_ENV_PATTERN = /^CLAUDE_TEAM_MODEL_([A-Z0-9_]+)_(PROVIDER|MODEL|URL|KEY|TEMP|MAX_TOKENS)$/;

/** ä¸“å®¶ç¯å¢ƒå˜é‡åŒ¹é…æ¨¡å¼ */
const EXPERT_ENV_PATTERN = /^CLAUDE_TEAM_EXPERT_([A-Z]+)_MODEL$/;

/** API Key ç¯å¢ƒå˜é‡åæ˜ å°„ */
const API_KEY_NAMES: Record<Provider, string> = {
  gemini: 'GEMINI_API_KEY',
  anthropic: 'ANTHROPIC_API_KEY',
  openai: 'OPENAI_API_KEY',
  ollama: 'OLLAMA_API_KEY',
};

/** å„æä¾›å•†çš„é»˜è®¤æ¨¡å‹ */
const DEFAULT_MODELS: Record<Provider, { model: string; tier: 'fast' | 'balanced' | 'powerful' }> = {
  gemini: { model: 'gemini-2.0-flash-exp', tier: 'fast' },
  anthropic: { model: 'claude-sonnet-4-20250514', tier: 'powerful' },
  openai: { model: 'gpt-4o', tier: 'balanced' },
  ollama: { model: 'llama3.2', tier: 'fast' },
};

/**
 * å¤šæ¨¡å‹é…ç½®ï¼ˆé€‚åˆä¸­è½¬ APIï¼‰
 * 
 * æ”¯æŒé…ç½®å¤šä¸ªæ¨¡å‹ï¼š
 * - MAIN: ä¸»æ¨¡å‹ï¼Œè´Ÿè´£åˆ†æä»»åŠ¡ã€åˆ†é…å·¥ä½œï¼Œä¹Ÿå¯å‚ä¸æ‰§è¡Œ
 * - MODEL1, MODEL2, MODEL3...: å·¥ä½œæ¨¡å‹ï¼Œå„è‡ªæ‰§è¡Œæ“…é•¿çš„ä»»åŠ¡
 */
interface MultiModelConfig {
  apiKey: string;
  baseUrl?: string;
  model: string;
  name: string;
  provider?: Provider;
}

/**
 * è§£æå¤šæ¨¡å‹é…ç½®
 * 
 * æ”¯æŒçš„ç¯å¢ƒå˜é‡ï¼š
 * - CLAUDE_TEAM_MAIN_KEY: ä¸»æ¨¡å‹ API Key
 * - CLAUDE_TEAM_MAIN_URL: ä¸»æ¨¡å‹ API åœ°å€
 * - CLAUDE_TEAM_MAIN_MODEL: ä¸»æ¨¡å‹ IDï¼ˆé»˜è®¤ gpt-4oï¼‰
 * - CLAUDE_TEAM_MAIN_PROVIDER: ä¸»æ¨¡å‹å“åº”æ ¼å¼ï¼ˆå¯é€‰ï¼Œopenai/anthropic/geminiï¼Œé»˜è®¤ openaiï¼‰
 * 
 * - CLAUDE_TEAM_MODEL1_KEY: æ¨¡å‹1 API Key
 * - CLAUDE_TEAM_MODEL1_URL: æ¨¡å‹1 API åœ°å€
 * - CLAUDE_TEAM_MODEL1_NAME: æ¨¡å‹1 ID
 * - CLAUDE_TEAM_MODEL1_PROVIDER: æ¨¡å‹1 å“åº”æ ¼å¼ï¼ˆå¯é€‰ï¼‰
 * 
 * - CLAUDE_TEAM_MODEL2_KEY/URL/NAME/PROVIDER: æ¨¡å‹2...
 * - CLAUDE_TEAM_MODEL3_KEY/URL/NAME/PROVIDER: æ¨¡å‹3...
 */
interface MultiModelSetup {
  main: MultiModelConfig;
  models: MultiModelConfig[];
}

function parseMultiModelConfig(): MultiModelSetup | null {
  const mainKey = process.env.CLAUDE_TEAM_MAIN_KEY;
  if (!mainKey) return null;
  
  const main: MultiModelConfig = {
    apiKey: mainKey,
    baseUrl: process.env.CLAUDE_TEAM_MAIN_URL,
    model: process.env.CLAUDE_TEAM_MAIN_MODEL || 'gpt-4o',
    name: 'main',
    provider: (process.env.CLAUDE_TEAM_MAIN_PROVIDER as Provider) || 'openai',
  };
  
  // è§£æå·¥ä½œæ¨¡å‹ MODEL1, MODEL2, MODEL3...
  const models: MultiModelConfig[] = [];
  
  for (let i = 1; i <= 10; i++) {
    const key = process.env[`CLAUDE_TEAM_MODEL${i}_KEY`];
    const url = process.env[`CLAUDE_TEAM_MODEL${i}_URL`];
    const name = process.env[`CLAUDE_TEAM_MODEL${i}_NAME`];
    const provider = process.env[`CLAUDE_TEAM_MODEL${i}_PROVIDER`] as Provider | undefined;
    
    // å¦‚æœæœ‰ KEY æˆ– NAMEï¼Œåˆ™æ·»åŠ æ¨¡å‹
    if (key || name) {
      models.push({
        apiKey: key || mainKey, // æ²¡æœ‰ç‹¬ç«‹ Key åˆ™ä½¿ç”¨ä¸»æ¨¡å‹çš„
        baseUrl: url || main.baseUrl, // æ²¡æœ‰ç‹¬ç«‹ URL åˆ™ä½¿ç”¨ä¸»æ¨¡å‹çš„
        model: name || main.model,
        name: `model${i}`,
        provider: provider || main.provider, // æ²¡æœ‰ç‹¬ç«‹ Provider åˆ™ä½¿ç”¨ä¸»æ¨¡å‹çš„
      });
    }
  }
  
  return { main, models };
}

/**
 * è§£æç®€åŒ–é…ç½®ï¼ˆå‘åå…¼å®¹ï¼‰
 * 
 * æ”¯æŒçš„ç¯å¢ƒå˜é‡ï¼š
 * - CLAUDE_TEAM_API_KEY: API Keyï¼ˆå¿…éœ€ï¼‰
 * - CLAUDE_TEAM_BASE_URL: API åœ°å€ï¼ˆå¯é€‰ï¼Œæ”¯æŒä¸­è½¬ï¼‰
 * - CLAUDE_TEAM_MODEL: æ¨¡å‹ IDï¼ˆå¯é€‰ï¼Œé»˜è®¤ gpt-4oï¼‰
 * - CLAUDE_TEAM_PROVIDER: æä¾›å•†ï¼ˆå¯é€‰ï¼Œé»˜è®¤ openaiï¼‰
 */
interface SimpleConfig {
  apiKey: string;
  baseUrl?: string;
  model: string;
  provider: Provider;
}

function parseSimpleConfig(): SimpleConfig | null {
  const apiKey = process.env.CLAUDE_TEAM_API_KEY;
  if (!apiKey) return null;
  
  return {
    apiKey,
    baseUrl: process.env.CLAUDE_TEAM_BASE_URL,
    model: process.env.CLAUDE_TEAM_MODEL || 'gpt-4o',
    provider: (process.env.CLAUDE_TEAM_PROVIDER || 'openai') as Provider,
  };
}

/**
 * æ£€æµ‹å¯ç”¨çš„ API Keys
 * ä¼˜å…ˆçº§ï¼šç®€åŒ–é…ç½® > ä¸“ç”¨ Key > é€šç”¨ Key
 * @returns å¯ç”¨çš„æä¾›å•†åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
 */
function detectAvailableProviders(): Provider[] {
  const available: Provider[] = [];
  
  // ä¼˜å…ˆæ£€æµ‹ç®€åŒ–é…ç½®
  const simpleConfig = parseSimpleConfig();
  if (simpleConfig) {
    // å°†ç®€åŒ–é…ç½®è®¾ç½®åˆ°å¯¹åº”çš„ç¯å¢ƒå˜é‡
    process.env[API_KEY_NAMES[simpleConfig.provider]] = simpleConfig.apiKey;
    if (simpleConfig.baseUrl) {
      process.env[`${simpleConfig.provider.toUpperCase()}_BASE_URL`] = simpleConfig.baseUrl;
    }
    available.push(simpleConfig.provider);
  }
  
  // æ£€æµ‹å„æä¾›å•†çš„ API Key
  const providers: Provider[] = ['gemini', 'anthropic', 'openai', 'ollama'];
  
  for (const provider of providers) {
    if (available.includes(provider)) continue;
    const keyName = API_KEY_NAMES[provider];
    if (process.env[keyName]) {
      available.push(provider);
    }
  }
  
  return available;
}

/**
 * ç”Ÿæˆå¤šæ¨¡å‹é…ç½®
 * æ”¯æŒ MAIN + MODEL1/2/3... å¤šæ¨¡å‹åä½œ
 * @returns è‡ªåŠ¨ç”Ÿæˆçš„é…ç½®
 */
function generateMultiModelConfig(): Config | null {
  const multiConfig = parseMultiModelConfig();
  if (!multiConfig) return null;
  
  const { main, models: workModels } = multiConfig;
  
  // è®¾ç½®ä¸»æ¨¡å‹ç¯å¢ƒå˜é‡
  process.env.OPENAI_API_KEY = main.apiKey;
  if (main.baseUrl) {
    process.env.OPENAI_BASE_URL = main.baseUrl;
  }
  
  // æ„å»ºæ¨¡å‹é…ç½®
  const models: Config['models'] = {};
  
  // ä¸»æ¨¡å‹ï¼ˆä¹Ÿå¯å‚ä¸ä»»åŠ¡æ‰§è¡Œï¼‰
  models['main'] = {
    provider: main.provider || 'openai',
    model: main.model,
    baseUrl: main.baseUrl,
    temperature: 0.3,
    maxTokens: 8192,
    tier: 'powerful',
  };
  
  // å·¥ä½œæ¨¡å‹
  for (const workModel of workModels) {
    models[workModel.name] = {
      provider: workModel.provider || 'openai',
      model: workModel.model,
      baseUrl: workModel.baseUrl,
      temperature: 0.7,
      maxTokens: 8192,
      tier: 'balanced',
    };
    
    // å¦‚æœæœ‰ç‹¬ç«‹çš„ Keyï¼Œè®¾ç½®ä¸“ç”¨ç¯å¢ƒå˜é‡
    if (workModel.apiKey !== main.apiKey) {
      process.env[`OPENAI_API_KEY_${workModel.name.toUpperCase()}`] = workModel.apiKey;
    }
  }
  
  // æ„å»ºæ¨¡å‹æ± 
  const allModelNames = ['main', ...workModels.map(m => m.name)];
  const modelPool = {
    fast: allModelNames[1] || 'main',
    balanced: allModelNames[Math.floor(allModelNames.length / 2)] || 'main',
    powerful: 'main',
  };
  
  return {
    lead: {
      model: 'main',
      temperature: 0.3,
    },
    models,
    modelPool,
    collaboration: {
      maxIterations: 5,
      autoReview: true,
      verbose: false,
    },
  };
}

/**
 * ç”Ÿæˆå¿«é€Ÿå¯åŠ¨é…ç½®
 * åªéœ€ä¸€ä¸ª API Key å³å¯è¿è¡Œ
 * @returns è‡ªåŠ¨ç”Ÿæˆçš„é…ç½®
 */
function generateQuickStartConfig(): Config | null {
  // ä¼˜å…ˆä½¿ç”¨å¤šæ¨¡å‹é…ç½®
  const multiConfig = generateMultiModelConfig();
  if (multiConfig) return multiConfig;
  
  const available = detectAvailableProviders();
  
  if (available.length === 0) {
    return null;
  }
  
  // æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç®€åŒ–é…ç½®
  const simpleConfig = parseSimpleConfig();
  
  // é€‰æ‹©ä¸»è¦æä¾›å•†
  const primary = available[0];
  const primaryModel = DEFAULT_MODELS[primary];
  
  // æ„å»ºæ¨¡å‹é…ç½®
  const models: Config['models'] = {};
  const modelName = `auto-${primary}`;
  
  // å¦‚æœæœ‰ç®€åŒ–é…ç½®ï¼Œä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹å’Œ URL
  models[modelName] = {
    provider: primary,
    model: simpleConfig?.model || primaryModel.model,
    baseUrl: simpleConfig?.baseUrl,
    temperature: 0.7,
    maxTokens: 8192,
    tier: primaryModel.tier,
  };
  
  // å¦‚æœæœ‰å¤šä¸ªæä¾›å•†ï¼Œæ·»åŠ æ›´å¤šæ¨¡å‹
  for (const provider of available.slice(1, 3)) {
    const info = DEFAULT_MODELS[provider];
    models[`auto-${provider}`] = {
      provider,
      model: info.model,
      temperature: 0.7,
      maxTokens: 8192,
      tier: info.tier,
    };
  }
  
  // æ„å»ºæ¨¡å‹æ± ï¼ˆä½¿ç”¨å¯ç”¨çš„æ¨¡å‹ï¼‰
  const modelPool = {
    fast: modelName,
    balanced: modelName,
    powerful: modelName,
  };
  
  // å¦‚æœæœ‰å¤šä¸ªæ¨¡å‹ï¼Œä¼˜åŒ–åˆ†é…
  if (available.length >= 2) {
    const tiers = available.map(p => ({ provider: p, ...DEFAULT_MODELS[p] }));
    const fast = tiers.find(t => t.tier === 'fast') || tiers[0];
    const powerful = tiers.find(t => t.tier === 'powerful') || tiers[0];
    const balanced = tiers.find(t => t.tier === 'balanced') || tiers[0];
    
    modelPool.fast = `auto-${fast.provider}`;
    modelPool.balanced = `auto-${balanced.provider}`;
    modelPool.powerful = `auto-${powerful.provider}`;
  }
  
  return {
    lead: {
      model: modelName,
      temperature: 0.3,
    },
    models,
    modelPool,
    collaboration: {
      maxIterations: 5,
      autoReview: true,
      verbose: false,
    },
  };
}

/**
 * ä»ç¯å¢ƒå˜é‡è§£ææ¨¡å‹é…ç½®
 *
 * æ”¯æŒçš„ç¯å¢ƒå˜é‡æ ¼å¼ï¼š
 * - CLAUDE_TEAM_MODEL_<NAME>_PROVIDER=openai
 * - CLAUDE_TEAM_MODEL_<NAME>_MODEL=gpt-4o
 * - CLAUDE_TEAM_MODEL_<NAME>_URL=https://api.example.com/v1
 * - CLAUDE_TEAM_MODEL_<NAME>_KEY=sk-xxx
 * - CLAUDE_TEAM_MODEL_<NAME>_TEMP=0.7
 * - CLAUDE_TEAM_MODEL_<NAME>_MAX_TOKENS=8192
 *
 * @returns æ¨¡å‹é…ç½®æ˜ å°„
 */
function parseEnvModels(): Record<string, EnvModelConfig> {
  const models: Record<string, EnvModelConfig> = {};

  for (const [key, value] of Object.entries(process.env)) {
    const match = key.match(MODEL_ENV_PATTERN);
    if (!match || !value) continue;

    // è½¬æ¢æ¨¡å‹åï¼šMY_GPT -> my-gpt
    const modelName = match[1].toLowerCase().replace(/_/g, '-');
    const property = match[2];

    // åˆå§‹åŒ–æ¨¡å‹é…ç½®
    models[modelName] ??= { provider: 'openai', model: '' };

    // æ ¹æ®å±æ€§ç±»å‹è®¾ç½®å€¼
    switch (property) {
      case 'PROVIDER':
        models[modelName].provider = value as Provider;
        break;
      case 'MODEL':
        models[modelName].model = value;
        break;
      case 'URL':
        models[modelName].baseUrl = value;
        break;
      case 'KEY':
        models[modelName].apiKey = value;
        break;
      case 'TEMP':
        models[modelName].temperature = Number.parseFloat(value);
        break;
      case 'MAX_TOKENS':
        models[modelName].maxTokens = Number.parseInt(value, 10);
        break;
    }
  }

  return models;
}

/**
 * ä»ç¯å¢ƒå˜é‡è§£æä¸“å®¶æ¨¡å‹é…ç½®
 *
 * æ”¯æŒçš„ç¯å¢ƒå˜é‡æ ¼å¼ï¼š
 * - CLAUDE_TEAM_EXPERT_FRONTEND_MODEL=my-gemini
 * - CLAUDE_TEAM_EXPERT_BACKEND_MODEL=my-claude
 * - CLAUDE_TEAM_EXPERT_QA_MODEL=my-gpt
 *
 * @returns ä¸“å®¶æ¨¡å‹é…ç½®æ˜ å°„
 */
export function parseEnvExperts(): Record<string, { model: string }> {
  const experts: Record<string, { model: string }> = {};

  for (const [key, value] of Object.entries(process.env)) {
    const match = key.match(EXPERT_ENV_PATTERN);
    if (!match || !value) continue;

    const expertName = match[1].toLowerCase();
    experts[expertName] = { model: value };
  }

  return experts;
}

/**
 * é»˜è®¤é…ç½®
 * åŒ…å«æ¨¡å‹æ± é…ç½®ï¼Œæ”¯æŒåŠ¨æ€ä¸“å®¶åˆ†é…
 */
const DEFAULT_CONFIG: Config = {
  lead: {
    model: 'gpt-4o-mini',
    temperature: 0.3,
  },
  models: {
    'gemini-2.0-flash': {
      provider: 'gemini',
      model: 'gemini-2.0-flash-exp',
      temperature: 0.7,
      maxTokens: 8192,
      tier: 'fast',
    },
    'claude-sonnet-4': {
      provider: 'anthropic',
      model: 'claude-sonnet-4-20250514',
      temperature: 0.7,
      maxTokens: 8192,
      tier: 'powerful',
    },
    'gpt-4o': {
      provider: 'openai',
      model: 'gpt-4o',
      temperature: 0.7,
      maxTokens: 8192,
      tier: 'balanced',
    },
    'gpt-4o-mini': {
      provider: 'openai',
      model: 'gpt-4o-mini',
      temperature: 0.3,
      maxTokens: 4096,
      tier: 'fast',
    },
  },
  modelPool: {
    fast: 'gemini-2.0-flash',
    balanced: 'gpt-4o',
    powerful: 'claude-sonnet-4',
  },
  collaboration: {
    maxIterations: 5,
    autoReview: true,
    verbose: false,
  },
};

/**
 * è·å–é…ç½®æ–‡ä»¶æœç´¢è·¯å¾„
 * @param customPath - è‡ªå®šä¹‰é…ç½®è·¯å¾„
 * @returns é…ç½®æ–‡ä»¶è·¯å¾„åˆ—è¡¨
 */
function getConfigPaths(customPath?: string): string[] {
  const home = process.env.HOME ?? '';

  return [
    customPath,
    process.env.CLAUDE_TEAM_CONFIG,
    join(home, '.claude-team', 'config.yaml'),
    join(home, '.claude-team', 'config.yml'),
    join(process.cwd(), 'claude-team.yaml'),
    join(process.cwd(), 'claude-team.yml'),
  ].filter((p): p is string => Boolean(p));
}

/**
 * ä»æ–‡ä»¶åŠ è½½é…ç½®
 * @param paths - é…ç½®æ–‡ä»¶è·¯å¾„åˆ—è¡¨
 * @returns é…ç½®å¯¹è±¡
 */
function loadFromFile(paths: string[]): Config {
  for (const path of paths) {
    if (!existsSync(path)) continue;

    try {
      const content = readFileSync(path, 'utf-8');
      const parsed = parse(content);
      return deepMerge(DEFAULT_CONFIG, parsed);
    } catch (error) {
      console.error(`é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ ${path}:`, error);
    }
  }

  return DEFAULT_CONFIG;
}

/**
 * åº”ç”¨ç¯å¢ƒå˜é‡ä¸­çš„æ¨¡å‹é…ç½®
 * @param config - å½“å‰é…ç½®
 */
function applyEnvModels(config: Config): void {
  const envModels = parseEnvModels();

  for (const [name, modelConfig] of Object.entries(envModels)) {
    if (!modelConfig.model) continue;

    // æ·»åŠ /è¦†ç›–æ¨¡å‹é…ç½®
    config.models[name] = {
      provider: modelConfig.provider,
      model: modelConfig.model,
      baseUrl: modelConfig.baseUrl,
      temperature: modelConfig.temperature ?? 0.7,
      maxTokens: modelConfig.maxTokens ?? 8192,
    };

    // è®¾ç½® API Key åˆ°ç¯å¢ƒå˜é‡
    if (modelConfig.apiKey) {
      // è®¾ç½®æ¨¡å‹ä¸“ç”¨ Key
      const specificKeyName = `${modelConfig.provider.toUpperCase()}_API_KEY_${name.toUpperCase().replace(/-/g, '_')}`;
      process.env[specificKeyName] = modelConfig.apiKey;

      // è®¾ç½®é»˜è®¤ Keyï¼ˆå¦‚æœæœªè®¾ç½®ï¼‰
      const defaultKeyName = API_KEY_NAMES[modelConfig.provider];
      process.env[defaultKeyName] ??= modelConfig.apiKey;
    }
  }
}

/**
 * åº”ç”¨ç¯å¢ƒå˜é‡ä¸­çš„æ¨¡å‹æ± é…ç½®
 * @param config - å½“å‰é…ç½®
 */
function applyEnvModelPool(config: Config): void {
  // è¦†ç›– Tech Lead æ¨¡å‹
  const leadModel = process.env.CLAUDE_TEAM_LEAD_MODEL;
  if (leadModel) {
    config.lead.model = leadModel;
  }

  // è¦†ç›–æ¨¡å‹æ± é…ç½®
  const fastModel = process.env.CLAUDE_TEAM_POOL_FAST;
  const balancedModel = process.env.CLAUDE_TEAM_POOL_BALANCED;
  const powerfulModel = process.env.CLAUDE_TEAM_POOL_POWERFUL;

  if (fastModel) config.modelPool.fast = fastModel;
  if (balancedModel) config.modelPool.balanced = balancedModel;
  if (powerfulModel) config.modelPool.powerful = powerfulModel;
}

/**
 * åŠ è½½é…ç½®
 * ä¼˜å…ˆçº§ï¼šç¯å¢ƒå˜é‡ > é…ç½®æ–‡ä»¶ > å¿«é€Ÿå¯åŠ¨ > é»˜è®¤é…ç½®
 *
 * å¿«é€Ÿå¯åŠ¨æ¨¡å¼ï¼š
 * - åªéœ€è®¾ç½® GEMINI_API_KEY / ANTHROPIC_API_KEY / OPENAI_API_KEY ä¹‹ä¸€
 * - æˆ–è®¾ç½® CLAUDE_TEAM_API_KEY + CLAUDE_TEAM_PROVIDER
 * - ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ç”Ÿæˆæœ€ä¼˜é…ç½®
 *
 * @param configPath - è‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„
 * @returns éªŒè¯åçš„é…ç½®å¯¹è±¡
 */
export function loadConfig(configPath?: string): Config {
  // 1. è·å–é…ç½®æ–‡ä»¶è·¯å¾„
  const paths = getConfigPaths(configPath);

  // 2. å°è¯•ä»æ–‡ä»¶åŠ è½½é…ç½®
  let config = loadFromFile(paths);
  
  // 3. å¦‚æœæ²¡æœ‰é…ç½®æ–‡ä»¶ï¼Œå°è¯•å¿«é€Ÿå¯åŠ¨æ¨¡å¼
  const hasConfigFile = paths.some(p => existsSync(p));
  if (!hasConfigFile) {
    const quickConfig = generateQuickStartConfig();
    if (quickConfig) {
      config = quickConfig;
      // é™é»˜æ¨¡å¼ä¸‹ä¸è¾“å‡ºï¼Œé™¤éè®¾ç½®äº† verbose
      if (process.env.CLAUDE_TEAM_VERBOSE === 'true') {
        const providers = detectAvailableProviders();
        console.error(`ğŸš€ å¿«é€Ÿå¯åŠ¨æ¨¡å¼: æ£€æµ‹åˆ° ${providers.join(', ')} API Key`);
      }
    }
  }

  // 4. åº”ç”¨ç¯å¢ƒå˜é‡è¦†ç›–
  applyEnvModels(config);
  applyEnvModelPool(config);

  // 5. éªŒè¯å¹¶è¿”å›
  return ConfigSchema.parse(config);
}

/**
 * æ·±åº¦åˆå¹¶å¯¹è±¡
 * @param target - ç›®æ ‡å¯¹è±¡
 * @param source - æºå¯¹è±¡
 * @returns åˆå¹¶åçš„å¯¹è±¡
 */
function deepMerge<T extends object>(target: T, source: Partial<T>): T {
  const result = { ...target };

  for (const key in source) {
    const sourceValue = source[key];
    const targetValue = result[key];

    if (sourceValue === undefined) continue;

    // é€’å½’åˆå¹¶å¯¹è±¡ï¼ˆæ’é™¤æ•°ç»„ï¼‰
    if (
      typeof sourceValue === 'object' &&
      sourceValue !== null &&
      !Array.isArray(sourceValue) &&
      typeof targetValue === 'object' &&
      targetValue !== null
    ) {
      (result as Record<string, unknown>)[key] = deepMerge(
        targetValue as object,
        sourceValue as object
      );
    } else {
      (result as Record<string, unknown>)[key] = sourceValue;
    }
  }

  return result;
}

export { DEFAULT_CONFIG };
